# Domain-Translation-Papers
Collecting typical papers about image domain translation.

## 1.Paired Two Domains

|Name|Paper|Code|Publisher|Year|
|:----:|:-----|:----:|:----:|:----:|
|Pix2Pix|[Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/pdf/1611.07004.pdf)|[torch](https://github.com/phillipi/pix2pix),[pytorch](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)|CVPR|2017|
|Pix2PixHD|[High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs](https://github.com/NVIDIA/pix2pixHD)|[pytorch](https://github.com/NVIDIA/pix2pixHD)|CVPR|2018|

## 2.Single modal

### 2.1.Unpaired Two Domains

|Name|Paper|Code|Publisher|Year|
|:----:|:-----|:----:|:----:|:----:|
|CycleGAN|[Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/pdf/1703.10593.pdf)|[torch](https://github.com/junyanz/CycleGAN),[pytorch](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)|CVPR|2018|
|UAG|[Unsupervised Attention-guided Image-to-Image Translation](https://arxiv.org/pdf/1806.02311.pdf)|[tensorflow](https://github.com/AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation),[pytorch](https://github.com/yhlleo/uaggan)|NIPS|2018|

### 2.2.Unpaired Multi-domain:

|Name|Paper|Code|Publisher|Year|
|:----:|:-----|:----:|:----:|:----:|
|StarGAN|[StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation](https://arxiv.org/pdf/1711.09020.pdf)|[pytorch](https://github.com/yunjey/stargan)|CVPR|2018|
|GANimation|[GANimation: Anatomically-aware Facial Animation from a Single Image](https://arxiv.org/pdf/1807.09251.pdf)|[pytorch](https://github.com/albertpumarola/GANimation)|ECCV|2018|
|FUNIT|[Few-Shot Unsupervised Image-to-Image Translation](https://arxiv.org/pdf/1905.01723.pdf)|[pytorch](https://github.com/NVLabs/FUNIT)|arXiv|2019|

## 3.Multiple modals
   
### 3.1.Paired Multi-modal:
|Name|Paper|Code|Publisher|Year|
|:----:|:-----|:----:|:----:|:----:|
|BiCycleGAN|[Toward Multimodal Image-to-Image Translation](https://arxiv.org/pdf/1711.11586.pdf)|[pytorch](https://github.com/junyanz/BicycleGAN)|NIPS|2017|

### 3.2.Unpaired Multi-modal:
|Name|Paper|Code|Publisher|Year|
|:----:|:-----|:----:|:----:|:----:|
|MUNIT|[Multimodal Unsupervised Image-to-Image Translation](https://arxiv.org/pdf/1804.04732.pdf)|[pytorch](https://github.com/NVlabs/MUNIT)|ECCV|2018|
|CDD|[Image-to-image translation for cross-domain disentanglement](https://arxiv.org/pdf/1805.09730.pdf)|[tensorflow](https://github.com/agonzgarc/cross-domain-disen)|NIPS|2018|
|Augmented CycleGAN|[Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data](https://arxiv.org/pdf/1802.10151.pdf)|[pytorch](https://github.com/aalmah/augmented_cyclegan)|ICML|2018|
