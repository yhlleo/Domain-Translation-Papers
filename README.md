# Domain-Translation-Papers
Collections of typical papers about image domain translation.


## 1.Single modal

## 1.1.Paired Two Domains

|Name|Paper|Code|Publisher|Year|
|:----:|:-----|:----:|:----:|:----:|
|Pix2Pix|[Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/pdf/1611.07004.pdf)|[torch](https://github.com/phillipi/pix2pix),[pytorch](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)|CVPR|2017|
|Pix2PixHD|[High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs](https://github.com/NVIDIA/pix2pixHD)|[pytorch](https://github.com/NVIDIA/pix2pixHD)|CVPR|2018|

### 1.2.Unpaired Two Domains

|Name|Paper|Code|Publisher|Year|
|:----:|:-----|:----:|:----:|:----:|
|CycleGAN|[Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/pdf/1703.10593.pdf)|[torch](https://github.com/junyanz/CycleGAN),[pytorch](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)|CVPR|2018|
|UAG|[Unsupervised Attention-guided Image-to-Image Translation](https://arxiv.org/pdf/1806.02311.pdf)|[tensorflow](https://github.com/AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation),[pytorch](https://github.com/yhlleo/uaggan)|NIPS|2018|

### 1.3.Unpaired Multi-domain:

|Name|Paper|Code|Publisher|Year|
|:----:|:-----|:----:|:----:|:----:|
|StarGAN|[StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation](https://arxiv.org/pdf/1711.09020.pdf)|[pytorch](https://github.com/yunjey/stargan)|CVPR|2018|
|GANimation|[GANimation: Anatomically-aware Facial Animation from a Single Image](https://arxiv.org/pdf/1807.09251.pdf)|[pytorch](https://github.com/albertpumarola/GANimation)|ECCV|2018|
|FUNIT|[Few-Shot Unsupervised Image-to-Image Translation](https://arxiv.org/pdf/1905.01723.pdf)|[pytorch](https://github.com/NVLabs/FUNIT)|arXiv|2019|
|UGAN|[UGAN: Untraceable GAN for Multi-Domain Face Translation](https://arxiv.org/pdf/1907.11418.pdf)|-|arXiv|2019|
|StyleGAN2|[StyleGAN2 Distillation for Feed-forward Image Manipulation](https://arxiv.org/pdf/2003.03581.pdf)|[code](https://github.com/EvgenyKashin/stylegan2-distillation)|arXiv|2020|

## 2.Multiple modals
   
### 2.1.Paired Multi-modal:
|Name|Paper|Code|Publisher|Year|
|:----:|:-----|:----:|:----:|:----:|
|BiCycleGAN|[Toward Multimodal Image-to-Image Translation](https://arxiv.org/pdf/1711.11586.pdf)|[pytorch](https://github.com/junyanz/BicycleGAN)|NIPS|2017|

### 2.2.Unpaired Multi-modal:
|Name|Paper|Code|Publisher|Year|
|:----:|:-----|:----:|:----:|:----:|
|MUNIT|[Multimodal Unsupervised Image-to-Image Translation](https://arxiv.org/pdf/1804.04732.pdf)|[pytorch](https://github.com/NVlabs/MUNIT)|ECCV|2018|
|CDD|[Image-to-image translation for cross-domain disentanglement](https://arxiv.org/pdf/1805.09730.pdf)|[tensorflow](https://github.com/agonzgarc/cross-domain-disen)|NIPS|2018|
|Augmented CycleGAN|[Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data](https://arxiv.org/pdf/1802.10151.pdf)|[pytorch](https://github.com/aalmah/augmented_cyclegan)|ICML|2018|
|SMIT|[SMIT: Stochastic Multi-Label Image-to-Image Translation](https://arxiv.org/pdf/1812.03704.pdf)|-|ICCV Workshop|2018|
|DRIT|[Diverse Image-to-Image Translation via Disentangled Representations](https://arxiv.org/pdf/1808.00948.pdf)|[pytorch](https://github.com/HsinYingLee/DRIT)|ECCV|2018|
|DRIT++|[DRIT++: Diverse Image-to-Image Translation via Disentangled Representations](https://arxiv.org/pdf/1905.01270.pdf)|[pytorch](https://github.com/HsinYingLee/DRIT)|arXiv|2019|
|StarGAN v2|[StarGAN v2: Diverse Image Synthesis for Multiple Domains](https://arxiv.org/abs/1912.01865)|[pytorch](https://github.com/clovaai/stargan-v2)|CVPR|2020|
|GMM-UNIT|[GMM-UNIT: Unsupervised Multi-Domain and Multi-Modal Image-to-Image Translation via Attribute Gaussian Mixture Modeling](https://arxiv.org/pdf/2003.06788.pdf)|-|arXiv|2020|
